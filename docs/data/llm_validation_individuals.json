{
  "experiment": "individual_crime_prediction",
  "description": "Predict individual crime policy responses from other policy positions",
  "n_respondents": 200,
  "crime_variables": {
    "V241397": "Urban unrest response (1=solve problems of racism/police violence, 7=use all available force)",
    "V241308x": "Death penalty (1=favor strongly, 2=favor not strongly, 3=oppose not strongly, 4=oppose strongly)",
    "V241272x": "Federal crime spending (1=increased a lot, 2=increased a little, 3=kept the same, 4=decreased a little, 5=decreased a lot)"
  },
  "models": {
    "ideology_only": {
      "per_question": {
        "urban_unrest": {
          "correct_pct": 31.5,
          "within_1_pct": 48.0,
          "mean_error": 2.015,
          "n": 200
        },
        "death_penalty": {
          "correct_pct": 34.0,
          "within_1_pct": 63.0,
          "mean_error": 1.15,
          "n": 200
        },
        "crime_spending": {
          "correct_pct": 41.0,
          "within_1_pct": 77.0,
          "mean_error": 0.89,
          "n": 200
        }
      },
      "mean_error": 1.3516666666666668
    },
    "full_model": {
      "per_question": {
        "urban_unrest": {
          "correct_pct": 31.5,
          "within_1_pct": 49.5,
          "mean_error": 2.03,
          "n": 200
        },
        "death_penalty": {
          "correct_pct": 39.5,
          "within_1_pct": 72.0,
          "mean_error": 1.005,
          "n": 200
        },
        "crime_spending": {
          "correct_pct": 48.0,
          "within_1_pct": 75.0,
          "mean_error": 0.835,
          "n": 200
        }
      },
      "mean_error": 1.29
    }
  },
  "detailed_results": {
    "ideology_only": [
      {
        "respondent_id": 1,
        "predictions": {
          "urban_unrest": 2.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 3.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 2,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 3,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 4.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 2.0
        }
      },
      {
        "respondent_id": 4,
        "predictions": {
          "urban_unrest": 2.0,
          "death_penalty": 2.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 4.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 5,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 3.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 5.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 2.0
        }
      },
      {
        "respondent_id": 6,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 3.0,
          "V241272x": 4.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 7,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 8,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 3.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 9,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 10,
        "predictions": {
          "urban_unrest": 2.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 2.3333333333333335
        }
      },
      {
        "respondent_id": 11,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 12,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 13,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 14,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 6.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 3.0
        }
      },
      {
        "respondent_id": 15,
        "predictions": {
          "urban_unrest": 2.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 2.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 16,
        "predictions": {
          "urban_unrest": 2.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 17,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 3.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 18,
        "predictions": {
          "urban_unrest": 2.0,
          "death_penalty": 3.0,
          "crime_spending": 3.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 3.0,
          "V241272x": 4.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 19,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 2.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 3.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 20,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 21,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 4.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 22,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 2.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 2.0
        }
      },
      {
        "respondent_id": 23,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 4.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 24,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 6.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 2.6666666666666665
        }
      },
      {
        "respondent_id": 25,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 26,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 27,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 28,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 3.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 3.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 29,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 4.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 30,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 2.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 31,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 6.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 2.0
        }
      },
      {
        "respondent_id": 32,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 33,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 34,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 2.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 5.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 2.3333333333333335
        }
      },
      {
        "respondent_id": 35,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 4.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 36,
        "predictions": {
          "urban_unrest": 3.0,
          "death_penalty": 4.0,
          "crime_spending": 3.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 2.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 37,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 2.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 2.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 38,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 3.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 39,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 3.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 40,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 2.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 4.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 2.3333333333333335
        }
      },
      {
        "respondent_id": 41,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 4.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 42,
        "predictions": {
          "urban_unrest": 2.0,
          "death_penalty": 2.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 43,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.0
        }
      },
      {
        "respondent_id": 44,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 1.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 45,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 4.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 46,
        "predictions": {
          "urban_unrest": 2.0,
          "death_penalty": 2.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 47,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 2.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 48,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 3.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 2.0
        }
      },
      {
        "respondent_id": 49,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 50,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.0
        }
      },
      {
        "respondent_id": 51,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 2.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 52,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 4.0,
          "crime_spending": 5.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            }
          },
          "mean_error": 2.3333333333333335
        }
      },
      {
        "respondent_id": 53,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 3.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 54,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 55,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 4.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 56,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.0
        }
      },
      {
        "respondent_id": 57,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 58,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 5.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 2.6666666666666665
        }
      },
      {
        "respondent_id": 59,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 60,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 2.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 4.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 61,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 2.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 62,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 2.0
        }
      },
      {
        "respondent_id": 63,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 3.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 64,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 1.0,
          "V241272x": 4.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            }
          },
          "mean_error": 2.6666666666666665
        }
      },
      {
        "respondent_id": 65,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 6.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 3.0
        }
      },
      {
        "respondent_id": 66,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 4.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 67,
        "predictions": {
          "urban_unrest": 2.0,
          "death_penalty": 2.0,
          "crime_spending": 3.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 68,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 6.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 3.0
        }
      },
      {
        "respondent_id": 69,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 70,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 3.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 71,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 3.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 72,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 2.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 2.0
        }
      },
      {
        "respondent_id": 73,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 74,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 75,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 76,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 5.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 2.6666666666666665
        }
      },
      {
        "respondent_id": 77,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 3.0,
          "V241272x": 5.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            }
          },
          "mean_error": 2.6666666666666665
        }
      },
      {
        "respondent_id": 78,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 2.0,
          "V241272x": 4.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 79,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 4.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 80,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 3.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 81,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 4.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 82,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 3.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 83,
        "predictions": {
          "urban_unrest": 3.0,
          "death_penalty": 2.0,
          "crime_spending": 3.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 2.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 84,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 85,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 4.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 86,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 3.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 87,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 88,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 6.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 2.3333333333333335
        }
      },
      {
        "respondent_id": 89,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 3.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.0
        }
      },
      {
        "respondent_id": 90,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 2.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 91,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 2.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 2.0
        }
      },
      {
        "respondent_id": 92,
        "predictions": {
          "urban_unrest": 2.0,
          "death_penalty": 2.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 4.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 93,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 4.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 94,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 6.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 2.6666666666666665
        }
      },
      {
        "respondent_id": 95,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 96,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 4.0,
          "V241272x": 4.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            }
          },
          "mean_error": 2.0
        }
      },
      {
        "respondent_id": 97,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 6.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 2.3333333333333335
        }
      },
      {
        "respondent_id": 98,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 3.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 4.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 2.3333333333333335
        }
      },
      {
        "respondent_id": 99,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 6.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 2.6666666666666665
        }
      },
      {
        "respondent_id": 100,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 3.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 2.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 101,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 6.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 3.0
        }
      },
      {
        "respondent_id": 102,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 6.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 2.3333333333333335
        }
      },
      {
        "respondent_id": 103,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 104,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 2.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 5.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 2.3333333333333335
        }
      },
      {
        "respondent_id": 105,
        "predictions": {
          "urban_unrest": 2.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 106,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.0
        }
      },
      {
        "respondent_id": 107,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 108,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 109,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 4.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 3.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 110,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 4.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 111,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 4.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 112,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 3.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 113,
        "predictions": {
          "urban_unrest": 2.0,
          "death_penalty": 2.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 2.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 114,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 2.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 3.0,
          "V241272x": 4.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 115,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 3.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 116,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 3.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 117,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 2.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 3.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 118,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 2.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 119,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 5.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 120,
        "predictions": {
          "urban_unrest": 2.0,
          "death_penalty": 3.0,
          "crime_spending": 3.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 2.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 121,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 5.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 3.0
        }
      },
      {
        "respondent_id": 122,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 123,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 6.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 3.3333333333333335
        }
      },
      {
        "respondent_id": 124,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 2.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 5.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 2.3333333333333335
        }
      },
      {
        "respondent_id": 125,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 126,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 127,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 6.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 2.6666666666666665
        }
      },
      {
        "respondent_id": 128,
        "predictions": {
          "urban_unrest": 3.0,
          "death_penalty": 2.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 3.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 129,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 4.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 2.3333333333333335
        }
      },
      {
        "respondent_id": 130,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 131,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 2.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 132,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 4.0,
          "crime_spending": 4.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 2.3333333333333335
        }
      },
      {
        "respondent_id": 133,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 3.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.0
        }
      },
      {
        "respondent_id": 134,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 4.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 135,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 6.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 3.0
        }
      },
      {
        "respondent_id": 136,
        "predictions": {
          "urban_unrest": 2.0,
          "death_penalty": 2.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 3.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 137,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 138,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 3.0,
          "V241272x": 4.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 139,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 3.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 140,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 141,
        "predictions": {
          "urban_unrest": 2.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 3.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 142,
        "predictions": {
          "urban_unrest": 2.0,
          "death_penalty": 2.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 4.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 143,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 3.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 144,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 3.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 145,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 2.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 146,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 1.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 147,
        "predictions": {
          "urban_unrest": 3.0,
          "death_penalty": 2.0,
          "crime_spending": 3.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 2.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 148,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 2.6666666666666665
        }
      },
      {
        "respondent_id": 149,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 3.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 2.0
        }
      },
      {
        "respondent_id": 150,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 4.0,
          "V241272x": 4.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            }
          },
          "mean_error": 2.3333333333333335
        }
      },
      {
        "respondent_id": 151,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 2.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.0
        }
      },
      {
        "respondent_id": 152,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 3.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 153,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 154,
        "predictions": {
          "urban_unrest": 4.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 1.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 155,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 156,
        "predictions": {
          "urban_unrest": 2.0,
          "death_penalty": 2.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 2.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 157,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 2.6666666666666665
        }
      },
      {
        "respondent_id": 158,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 159,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 3.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 160,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 5.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 2.6666666666666665
        }
      },
      {
        "respondent_id": 161,
        "predictions": {
          "urban_unrest": 2.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 2.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 162,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 3.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 163,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 4.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 164,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 165,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 166,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 3.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 2.0
        }
      },
      {
        "respondent_id": 167,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 4.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 168,
        "predictions": {
          "urban_unrest": 2.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 169,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 170,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 4.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 5.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 2.0
        }
      },
      {
        "respondent_id": 171,
        "predictions": {
          "urban_unrest": 2.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 172,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 4.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 173,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 2.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 4.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 174,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 4.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 6.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 3.0
        }
      },
      {
        "respondent_id": 175,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 3.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 176,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 3.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 177,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.0
        }
      },
      {
        "respondent_id": 178,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 3.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 4.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 179,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 180,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 181,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 2.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 4.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 182,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.0
        }
      },
      {
        "respondent_id": 183,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 6.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 2.0
        }
      },
      {
        "respondent_id": 184,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 2.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 3.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 2.3333333333333335
        }
      },
      {
        "respondent_id": 185,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 1.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 186,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 2.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 2.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 187,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 188,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 2.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 4.0,
          "V241272x": 4.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 6.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 3.3333333333333335
        }
      },
      {
        "respondent_id": 189,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 2.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 1.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 190,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 3.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 191,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 4.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 192,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 3.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 193,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 5.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 194,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 3.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 195,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 6.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 3.0
        }
      },
      {
        "respondent_id": 196,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 197,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 198,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 199,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 200,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 2.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      }
    ],
    "full_model": [
      {
        "respondent_id": 1,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 3.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 2,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 3,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 4.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 5.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 3.3333333333333335
        }
      },
      {
        "respondent_id": 4,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 4.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 5,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 3.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 5.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 2.6666666666666665
        }
      },
      {
        "respondent_id": 6,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 3.0,
          "V241272x": 4.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 6.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            }
          },
          "mean_error": 3.6666666666666665
        }
      },
      {
        "respondent_id": 7,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 8,
        "predictions": {
          "urban_unrest": 2.0,
          "death_penalty": 2.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 3.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 9,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 10,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 11,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 12,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 6.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 2.3333333333333335
        }
      },
      {
        "respondent_id": 13,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 14,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.0
        }
      },
      {
        "respondent_id": 15,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 2.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 16,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 2.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 17,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 3.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 18,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 3.0,
          "V241272x": 4.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            }
          },
          "mean_error": 2.3333333333333335
        }
      },
      {
        "respondent_id": 19,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 3.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 2.3333333333333335
        }
      },
      {
        "respondent_id": 20,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 21,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 4.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 22,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 2.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 23,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 4.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 24,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.0
        }
      },
      {
        "respondent_id": 25,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 26,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 27,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 28,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 3.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 29,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 4.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 30,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 2.3333333333333335
        }
      },
      {
        "respondent_id": 31,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 32,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 33,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 34,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 2.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 5.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 2.3333333333333335
        }
      },
      {
        "respondent_id": 35,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 4.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 36,
        "predictions": {
          "urban_unrest": 2.0,
          "death_penalty": 3.0,
          "crime_spending": 3.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 2.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 37,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 2.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 2.0
        }
      },
      {
        "respondent_id": 38,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 3.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 2.3333333333333335
        }
      },
      {
        "respondent_id": 39,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 3.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 40,
        "predictions": {
          "urban_unrest": 2.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 4.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 2.3333333333333335
        }
      },
      {
        "respondent_id": 41,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 4.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 6.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 3.6666666666666665
        }
      },
      {
        "respondent_id": 42,
        "predictions": {
          "urban_unrest": 2.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 43,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.0
        }
      },
      {
        "respondent_id": 44,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 1.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 2.6666666666666665
        }
      },
      {
        "respondent_id": 45,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 4.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 46,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 5.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 2.3333333333333335
        }
      },
      {
        "respondent_id": 47,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 2.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 48,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 3.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 2.0
        }
      },
      {
        "respondent_id": 49,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 5.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 2.0
        }
      },
      {
        "respondent_id": 50,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 51,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 3.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 2.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 52,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 4.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 53,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 3.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 54,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 55,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 4.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 56,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.0
        }
      },
      {
        "respondent_id": 57,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 58,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 5.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 2.6666666666666665
        }
      },
      {
        "respondent_id": 59,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 60,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 4.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 5.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 2.3333333333333335
        }
      },
      {
        "respondent_id": 61,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 2.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 62,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 2.0
        }
      },
      {
        "respondent_id": 63,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 3.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 6.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 2.3333333333333335
        }
      },
      {
        "respondent_id": 64,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 1.0,
          "V241272x": 4.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            }
          },
          "mean_error": 2.0
        }
      },
      {
        "respondent_id": 65,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 66,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 4.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 67,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 68,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 6.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 3.3333333333333335
        }
      },
      {
        "respondent_id": 69,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 70,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 3.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 71,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 3.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 72,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 2.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 73,
        "predictions": {
          "urban_unrest": 2.0,
          "death_penalty": 2.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 74,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 75,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 6.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 2.0
        }
      },
      {
        "respondent_id": 76,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 77,
        "predictions": {
          "urban_unrest": 2.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 3.0,
          "V241272x": 5.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            }
          },
          "mean_error": 2.3333333333333335
        }
      },
      {
        "respondent_id": 78,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 2.0,
          "V241272x": 4.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 79,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 4.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 80,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 3.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 81,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 4.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            }
          },
          "mean_error": 2.0
        }
      },
      {
        "respondent_id": 82,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 3.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 83,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 2.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 84,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 2.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 85,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 4.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 86,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 3.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 87,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 88,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 2.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 89,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 3.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 90,
        "predictions": {
          "urban_unrest": 2.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 2.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 91,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 2.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 2.0
        }
      },
      {
        "respondent_id": 92,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 4.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 3.0
        }
      },
      {
        "respondent_id": 93,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 4.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 94,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.0
        }
      },
      {
        "respondent_id": 95,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 2.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 96,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 4.0,
          "V241272x": 4.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 97,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 2.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 6.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 2.0
        }
      },
      {
        "respondent_id": 98,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 4.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 2.0
        }
      },
      {
        "respondent_id": 99,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 100,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 2.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 101,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 102,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 6.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 2.3333333333333335
        }
      },
      {
        "respondent_id": 103,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 104,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 2.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 105,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 2.0
        }
      },
      {
        "respondent_id": 106,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.0
        }
      },
      {
        "respondent_id": 107,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 108,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 109,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 3.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 2.0
        }
      },
      {
        "respondent_id": 110,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 4.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 111,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 4.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 112,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 3.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 113,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 2.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 114,
        "predictions": {
          "urban_unrest": 2.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 3.0,
          "V241272x": 4.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            }
          },
          "mean_error": 2.0
        }
      },
      {
        "respondent_id": 115,
        "predictions": {
          "urban_unrest": 2.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 3.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 116,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 3.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 117,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 3.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 118,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 2.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 2.3333333333333335
        }
      },
      {
        "respondent_id": 119,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 120,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 2.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 2.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 121,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 122,
        "predictions": {
          "urban_unrest": 2.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 123,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 6.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 3.0
        }
      },
      {
        "respondent_id": 124,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 2.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 5.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 2.3333333333333335
        }
      },
      {
        "respondent_id": 125,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 2.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 126,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 127,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 6.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 2.0
        }
      },
      {
        "respondent_id": 128,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 3.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 129,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 4.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 2.3333333333333335
        }
      },
      {
        "respondent_id": 130,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 131,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 132,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 4.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 133,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 3.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 134,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 4.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 135,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 6.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 3.3333333333333335
        }
      },
      {
        "respondent_id": 136,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 3.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 137,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 138,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 3.0,
          "V241272x": 4.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 139,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 3.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 140,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 2.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 141,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 2.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 3.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 142,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 4.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 143,
        "predictions": {
          "urban_unrest": 2.0,
          "death_penalty": 2.0,
          "crime_spending": 3.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 3.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 144,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 3.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 145,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.0
        }
      },
      {
        "respondent_id": 146,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 1.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 147,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 2.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 148,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 2.6666666666666665
        }
      },
      {
        "respondent_id": 149,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 3.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 150,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 4.0,
          "V241272x": 4.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            }
          },
          "mean_error": 3.0
        }
      },
      {
        "respondent_id": 151,
        "predictions": {
          "urban_unrest": 2.0,
          "death_penalty": 2.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 152,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 3.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 153,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 154,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 1.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 155,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 156,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 2.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 157,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 2.6666666666666665
        }
      },
      {
        "respondent_id": 158,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 159,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 3.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 160,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 161,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 2.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 162,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 3.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 163,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 4.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 164,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 6.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 2.0
        }
      },
      {
        "respondent_id": 165,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 166,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 167,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 4.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 168,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 169,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 170,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 4.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 5.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 2.0
        }
      },
      {
        "respondent_id": 171,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 2.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.0
        }
      },
      {
        "respondent_id": 172,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 4.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 173,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 4.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 174,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 4.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 175,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 3.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 2.0
        }
      },
      {
        "respondent_id": 176,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 3.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 177,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.0
        }
      },
      {
        "respondent_id": 178,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 4.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 3.0
        }
      },
      {
        "respondent_id": 179,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 180,
        "predictions": {
          "urban_unrest": 2.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 181,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 4.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 5.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 2.6666666666666665
        }
      },
      {
        "respondent_id": 182,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 6.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 2.0
        }
      },
      {
        "respondent_id": 183,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 6.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 2.0
        }
      },
      {
        "respondent_id": 184,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 3.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 2.3333333333333335
        }
      },
      {
        "respondent_id": 185,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 1.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 186,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 2.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 187,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 188,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 4.0,
          "V241272x": 4.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            }
          },
          "mean_error": 1.3333333333333333
        }
      },
      {
        "respondent_id": 189,
        "predictions": {
          "urban_unrest": 2.0,
          "death_penalty": 2.0,
          "crime_spending": 3.0
        },
        "ground_truth": {
          "V241397": 3.0,
          "V241308x": 1.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 190,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 3.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 0.3333333333333333
        }
      },
      {
        "respondent_id": 191,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 4.0,
          "V241272x": 3.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 192,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 3.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 2.0
        }
      },
      {
        "respondent_id": 193,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 2.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 5.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      },
      {
        "respondent_id": 194,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 3.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 195,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 6.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            }
          },
          "mean_error": 3.0
        }
      },
      {
        "respondent_id": 196,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 4.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 7.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 6.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 2.6666666666666665
        }
      },
      {
        "respondent_id": 197,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 4.0,
          "V241308x": 1.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 3.0
            },
            "death_penalty": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.0
        }
      },
      {
        "respondent_id": 198,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 2.0
        },
        "ground_truth": {
          "V241397": 1.0,
          "V241308x": 1.0,
          "V241272x": 2.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 0,
              "error": 2.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 199,
        "predictions": {
          "urban_unrest": 7.0,
          "death_penalty": 1.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 6.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 0.6666666666666666
        }
      },
      {
        "respondent_id": 200,
        "predictions": {
          "urban_unrest": 1.0,
          "death_penalty": 3.0,
          "crime_spending": 1.0
        },
        "ground_truth": {
          "V241397": 5.0,
          "V241308x": 2.0,
          "V241272x": 1.0
        },
        "metrics": {
          "per_question": {
            "urban_unrest": {
              "correct": 0,
              "within_1": 0,
              "error": 4.0
            },
            "death_penalty": {
              "correct": 0,
              "within_1": 1,
              "error": 1.0
            },
            "crime_spending": {
              "correct": 1,
              "within_1": 1,
              "error": 0.0
            }
          },
          "mean_error": 1.6666666666666667
        }
      }
    ]
  }
}